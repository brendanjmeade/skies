{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "\n",
    "import skies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_name = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "base_runs_folder = \"./runs/\"\n",
    "output_path = os.path.join(base_runs_folder, run_name)\n",
    "mesh_parameters_file_name = \"western_north_america_mesh_parameters.json\"\n",
    "skies.create_output_folder(base_runs_folder, output_path)\n",
    "meshes = skies.read_meshes(mesh_parameters_file_name)\n",
    "skies.print_magnitude_overview(meshes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial conditions with accumulated slip\n",
    "sources = addict.Dict()\n",
    "sources.lon = np.array([235.779])\n",
    "sources.lat = np.array([45.553])\n",
    "sources.magnitude = np.array([10.0])\n",
    "sources.slip_type = [\"dip_slip\"]\n",
    "initial_slip_deficit = skies.get_synthetic_accumulated_slip(meshes[0], sources)\n",
    "initial_dip_slip_deficit = initial_slip_deficit[1::2]\n",
    "\n",
    "# Load initial slip defict and multiply by time cascadia_low_resolution_tde_dip_slip_rates.npy\n",
    "initial_dip_slip_deficit = np.load(\"cascadia_low_resolution_tde_dip_slip_rates.npy\")\n",
    "\n",
    "total_coseismic_slip = np.zeros_like(initial_dip_slip_deficit)\n",
    "skies.plot_initial_data(meshes, initial_dip_slip_deficit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event basics\n",
    "event = addict.Dict()\n",
    "event.moment_magnitude = 6.0\n",
    "event.hypocenter_longitude = 235.87495333  #  (degrees)\n",
    "event.hypocenter_latitude = 40.94505867  #  (degrees)\n",
    "event.hypocenter_depth = -15.36972933  # (km)\n",
    "event.shear_modulus = 3e10\n",
    "event.area_scaling = 1.25\n",
    "# event = skies.get_event_area_slip_triangle_index(meshes[0], event)\n",
    "event = skies.get_event_area_slip_hypocenter(meshes[0], event)\n",
    "\n",
    "# Run parameters\n",
    "params = addict.Dict()\n",
    "params.n_grid_longitude = 1000\n",
    "params.n_grid_latitude = 1000\n",
    "params.min_longitude = 231.0\n",
    "params.max_longitude = 239.0\n",
    "params.min_latitude = 38.0\n",
    "params.max_latitude = 52.0\n",
    "params.n_contour_levels = 10\n",
    "params.min_contour_value = 0.1  # (m)\n",
    "params.savefig = True\n",
    "params.run_name = run_name\n",
    "\n",
    "# # Plot event eigenmodes\n",
    "# skies.plot_event_select_eigenmodes(meshes[0], event, params)\n",
    "\n",
    "# # Plot event slip\n",
    "skies.quick_plot_slip(meshes[0], event, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def get_omori_decay_probability(time_vector, time_of_earthquake, amplitude, decay_time):\n",
    "    omori_decay_probability = amplitude / (\n",
    "        1 + (1 / decay_time) * (time_vector - time_of_earthquake)\n",
    "    )\n",
    "\n",
    "    omori_decay_probability[time_vector < time_of_earthquake] = 0.0\n",
    "    return omori_decay_probability\n",
    "\n",
    "\n",
    "MM2M = 1e-3  # millimeters to meters\n",
    "SECONDS_IN_A_YEAR = 60 * 60 * 24 * 365\n",
    "DAYS_IN_A_YEAR = 365\n",
    "n_years = 100\n",
    "time_vector = np.linspace(0, n_years, n_years * 1)\n",
    "minimum_probability = 1e-5\n",
    "time_probability = np.zeros_like(time_vector)\n",
    "time_probability = minimum_probability * np.ones_like(time_vector)\n",
    "\n",
    "# loading_rate = 30.0  # (mm/yr)\n",
    "earthquake_index_list = []\n",
    "earthquake_magnitude_list = []\n",
    "earthquake_probability_list = []\n",
    "event_trigger_list = []\n",
    "\n",
    "b_value = -1.0\n",
    "minimum_event_moment_magnitude = 7.0\n",
    "maximum_event_moment_magnitude = 9.0\n",
    "\n",
    "amplitude = 0.01\n",
    "\n",
    "# Initial conditions\n",
    "pre_event_slip_deficit = np.copy(initial_dip_slip_deficit)\n",
    "total_slip_deficit = 1e-1 * np.copy(initial_dip_slip_deficit)\n",
    "total_slip_deficit_scalar = np.zeros_like(time_vector)\n",
    "total_slip_deficit_scalar[0] = np.sum(total_slip_deficit)\n",
    "\n",
    "# Intial geometric moment deficit and storage\n",
    "total_geometric_moment_deficit = initial_dip_slip_deficit * meshes[0].areas\n",
    "total_geometric_moment_deficit_scalar = np.zeros_like(time_vector)\n",
    "total_geometric_moment_deficit_scalar[0] = np.sum(\n",
    "    initial_dip_slip_deficit * meshes[0].areas\n",
    ")\n",
    "\n",
    "time_step = 1e-6\n",
    "interseismic_loading_rate = initial_dip_slip_deficit\n",
    "time_probability_step = 0.00005\n",
    "time_probability_step = 1e-10\n",
    "\n",
    "candidate_event = addict.Dict()\n",
    "\n",
    "# Main time loop\n",
    "for i in range(0, len(time_vector) - 1):\n",
    "\n",
    "    # Determine whether there is an event at this time step\n",
    "    event_trigger = np.random.choice(\n",
    "        2, 1, p=[1 - time_probability[i], time_probability[i]]\n",
    "    )\n",
    "    event_trigger_list.append(event_trigger)\n",
    "\n",
    "    # Magnitude of candidate earthquake\n",
    "    candidate_event.moment_magnitude = skies.get_gutenberg_richter_magnitude(\n",
    "        b_value, minimum_event_moment_magnitude, maximum_event_moment_magnitude\n",
    "    )\n",
    "\n",
    "    # Do we have enough stored moment for a candidate event of this size\n",
    "    # Candidate event moment and geometric moment\n",
    "    AREA_SCALING = 1.25\n",
    "    candidate_event.moment = 10 ** (\n",
    "        1.5 * (candidate_event.moment_magnitude + 10.7) - 7.0\n",
    "    )\n",
    "    SHEAR_MODULUS = 3e10\n",
    "    candidate_event.geometric_moment = candidate_event.moment / SHEAR_MODULUS\n",
    "    if candidate_event.geometric_moment < total_geometric_moment_deficit_scalar[i]:\n",
    "        geometric_moment_condition = True\n",
    "    else:\n",
    "        geometric_moment_condition = False\n",
    "        print(f\"Geometric moment conditions fails at: {i=}\")\n",
    "\n",
    "    # Do we have an earthquake at this time step?\n",
    "    if bool(event_trigger) and (np.sum(total_slip_deficit) > 0):\n",
    "        print(f\"Earthquake at time step: {i}\")\n",
    "        # Generate a synthetic earthquake\n",
    "        location_probability = skies.get_location_probability(pre_event_slip_deficit)\n",
    "\n",
    "        # TODO: Unbundle event creation\n",
    "        # skies.create_event_target(meshes, magnitude, hypocenter_location)\n",
    "        event = skies.create_event(meshes, location_probability)\n",
    "        event.location_probability = location_probability\n",
    "        event.pre_event_slip_deficit = pre_event_slip_deficit\n",
    "        event.post_event_slip_deficit = pre_event_slip_deficit - event.slip_all_elements\n",
    "\n",
    "        earthquake_magnitude_list.append(event.moment_magnitude)\n",
    "        earthquake_index_list.append(i)\n",
    "        earthquake_probability_list.append(\n",
    "            get_omori_decay_probability(\n",
    "                time_vector, time_vector[i], amplitude, decay_time=100.0\n",
    "            )\n",
    "        )\n",
    "        event.magnitude_dependent_amplitude = (\n",
    "            amplitude + amplitude * event.moment_magnitude / 500\n",
    "        )\n",
    "\n",
    "        # Update the total slip deficit mesh\n",
    "        total_slip_deficit = (\n",
    "            total_slip_deficit\n",
    "            + time_step * interseismic_loading_rate\n",
    "            - event.slip_all_elements\n",
    "        )\n",
    "\n",
    "        # Update probability for event occurrence at the next time step\n",
    "        time_probability[i + 1] = (\n",
    "            time_probability[i] + time_step + event.magnitude_dependent_amplitude\n",
    "        )\n",
    "\n",
    "        # Save event dictionary as pickle file\n",
    "        event_pickle_file_name = f\"{output_path}/event_{i:010.0f}.pickle\"\n",
    "        with open(event_pickle_file_name, \"wb\") as pickle_file:\n",
    "            pickle.dump(event, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    else:\n",
    "        # Update total_slip_deficit for the case when there are no earthquakes\n",
    "        total_slip_deficit = total_slip_deficit + time_step * interseismic_loading_rate\n",
    "\n",
    "        # Update time probability for event occurence at the next time step\n",
    "        time_probability[i + 1] = time_probability[i] + time_step * np.sum(\n",
    "            interseismic_loading_rate\n",
    "        )\n",
    "\n",
    "        # Sum contribution from all past earthquakes\n",
    "        # TODO: The scaling factor here is magic\n",
    "        for j in range(len(earthquake_index_list)):\n",
    "            time_probability[i + 1] += 1.5 * (\n",
    "                earthquake_probability_list[j][i + 1]\n",
    "                - earthquake_probability_list[j][i]\n",
    "            )\n",
    "\n",
    "    total_geometric_moment_deficit_scalar[i + 1] = np.sum(\n",
    "        total_slip_deficit * meshes[0].areas\n",
    "    )\n",
    "\n",
    "    # Update the total slip deficit scalar\n",
    "    total_slip_deficit_scalar[i + 1] = np.sum(total_slip_deficit)\n",
    "\n",
    "    # Pre-event slip deficit for next time step\n",
    "    pre_event_slip_deficit = np.copy(total_slip_deficit)\n",
    "\n",
    "    # Catch probabilities less than zero\n",
    "    if time_probability[i + 1] < minimum_probability:\n",
    "        time_probability[i + 1] = minimum_probability\n",
    "        print(f\"time_probability < 0.0 at step {i}\")\n",
    "\n",
    "    # Catch probabilities greater than one\n",
    "    if time_probability[i + 1] >= 1.0:\n",
    "        time_probability[i + 1] = 1.0\n",
    "        print(f\"time_probability > 1.0 at step {i}\")\n",
    "\n",
    "print(np.where(np.array(event_trigger_list) == 1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "end_idx = 400000\n",
    "figsize = (15, 3)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "# plt.plot(\n",
    "#     [np.min(time_vector[start_idx:end_idx]), np.max(time_vector[start_idx:end_idx])],\n",
    "#     [0, 0],\n",
    "#     \"-k\",\n",
    "#     linewidth=0.5,\n",
    "# )\n",
    "plt.plot(\n",
    "    time_vector[start_idx:end_idx],\n",
    "    total_slip_deficit_scalar[start_idx:end_idx],\n",
    "    \"-r\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"$\\hat{s}_\\mathrm{d}$ (m)\")\n",
    "# plt.xlim([np.min(time_vector), np.max(time_vector)])\n",
    "# plt.ylim([1e-4, 1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(event_trigger_list[start_idx:end_idx], \"r.\")\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"event_trigger\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability in time: Semilogy plot\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.semilogy(time_vector, time_probability, \"-k\", linewidth=0.5, zorder=35)\n",
    "fill_x = np.append(time_vector, np.array([np.max(time_vector), 0]))\n",
    "fill_y = np.append(\n",
    "    time_probability, np.array([minimum_probability, minimum_probability])\n",
    ")\n",
    "plt.fill(\n",
    "    fill_x,\n",
    "    fill_y,\n",
    "    color=\"lightsteelblue\",\n",
    "    alpha=1.0,\n",
    "    edgecolor=None,\n",
    "    zorder=10,\n",
    ")\n",
    "\n",
    "cmap = cc.cm.CET_L17\n",
    "magnitude_plot_size = 1e-5 * 10 ** np.array(earthquake_magnitude_list)\n",
    "plt.scatter(\n",
    "    time_vector[earthquake_index_list],\n",
    "    time_probability[earthquake_index_list],\n",
    "    s=magnitude_plot_size,\n",
    "    c=earthquake_magnitude_list,\n",
    "    zorder=20,\n",
    "    alpha=0.65,\n",
    "    cmap=cmap,\n",
    "    edgecolors=None,\n",
    "    linewidths=0.25,\n",
    "    vmin=6.0,\n",
    "    vmax=9.0,\n",
    ")\n",
    "cb = plt.colorbar(\n",
    "    cax=plt.gca().inset_axes((0.02, 0.94, 0.15, 0.03)),\n",
    "    label=\"magnitude\",\n",
    "    orientation=\"horizontal\",\n",
    "    ticks=[6, 7, 8, 9],\n",
    ")\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.plot(\n",
    "    time_vector[earthquake_index_list],\n",
    "    time_probability[earthquake_index_list],\n",
    "    \".k\",\n",
    "    markersize=3,\n",
    "    zorder=50,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.xlim([np.min(time_vector), np.max(time_vector)])\n",
    "plt.ylim([1e-4, 1])\n",
    "# plt.savefig(\"example_probability_time_series_semilogy.pdf\")\n",
    "# plt.savefig(\"example_probability_time_series_semilogy.png\", dpi=500)\n",
    "plt.show()\n",
    "\n",
    "# Earthquake magnitude plot\n",
    "plt.figure(figsize=(10, 3))\n",
    "for i in range(len(earthquake_index_list)):\n",
    "    plt.plot(\n",
    "        [time_vector[earthquake_index_list[i]], time_vector[earthquake_index_list[i]]],\n",
    "        [6.0, earthquake_magnitude_list[i]],\n",
    "        \"-\",\n",
    "        # markersize=10**(earthquake_magnitude_list[i] - 6),\n",
    "        linewidth=0.25,\n",
    "        zorder=10,\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "\n",
    "cmap = cc.cm.CET_L17\n",
    "magnitude_plot_size = 1e-5 * 10 ** np.array(earthquake_magnitude_list)\n",
    "plt.scatter(\n",
    "    time_vector[earthquake_index_list],\n",
    "    earthquake_magnitude_list,\n",
    "    s=magnitude_plot_size,\n",
    "    c=earthquake_magnitude_list,\n",
    "    zorder=20,\n",
    "    alpha=0.65,\n",
    "    cmap=cmap,\n",
    "    edgecolors=None,\n",
    "    linewidths=0.25,\n",
    "    vmin=6.0,\n",
    "    vmax=9.0,\n",
    ")\n",
    "\n",
    "# for i in range(len(earthquake_index_list)):\n",
    "#     plt.plot(\n",
    "#         time_vector[earthquake_index_list[i]],\n",
    "#         earthquake_magnitude_list[i],\n",
    "#         \".\",\n",
    "#         markersize=10 ** (earthquake_magnitude_list[i] - 6),\n",
    "#         # markersize=10,\n",
    "#         alpha=1.0,\n",
    "#         linewidth=0.0,\n",
    "#         zorder=20,\n",
    "#         color=\"orange\",\n",
    "#         markeredgecolor=\"k\",\n",
    "#         markeredgewidth=0.25,\n",
    "#     )\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"magnitude\")\n",
    "plt.xlim([np.min(time_vector), np.max(time_vector)])\n",
    "plt.ylim([6, 10])\n",
    "# plt.grid(True, linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "# plt.savefig(\"example_magnitude_time_series_semilogy.pdf\")\n",
    "# plt.savefig(\"example_magnitude_time_series_semilogy.png\", dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(event.slip_all_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_value = -1.0\n",
    "minimum_event_moment_magnitude = 7.0\n",
    "maximum_event_moment_magnitude = 9.0\n",
    "n = 10000\n",
    "temp = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    temp[i] = skies.get_gutenberg_richter_magnitude(\n",
    "        b_value, minimum_event_moment_magnitude, maximum_event_moment_magnitude\n",
    "    )\n",
    "plt.figure()\n",
    "plt.hist(temp, log=True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "958557df22cbe81e98d59acf449326e362496737a00c7832d7d66de975b82f73"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
