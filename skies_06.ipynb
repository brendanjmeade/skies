{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Kinematically Informed Earthquake Sequences (SKIES)\n",
    "1. Calculate kinematically informed random epicenter\n",
    "     $$P(c(t)) = \\frac{1}{1+e^{-c(t)}} + \\mathrm{history}$$\n",
    "     where $c(t)$ is the coupling rate at time ($t$).  This is an instantaneous formulation.  We could also do this with a more history dependent formulation.  This could include dropping probabilities after an event ruptures a triangular element much like a \"state\" effect.  This could sort of halo certain regions\n",
    "2. Calculate random magnitude from Gutenberg-Richter distribution with a minimum magnitude based on minimum triangle area \n",
    "3. Calculate approximate rupture area, $a$ with empirical scaling law (Allen and Hayes, 2017)\n",
    "4. Find subset of $n$ triangles with areas $a_n$ that sum to $a$ some factor\n",
    "5. Calculate eigenfunctions for these triangles\n",
    "6. Generate random Gaussian slip pattern from randomly weighted eigenvectors\n",
    "7. Sigmoid scaling of slip with distance from the hypocenter so that it tapers to zero at rupture edge\n",
    "8. Rescale random Gaussian slip pattern to get the magnitude correct\n",
    "\n",
    "# This model is consistent with:\n",
    "1. Gutenberg-Richter magnitude-frequency distribution\n",
    "2. Utsu-Omori aftershock decay rate\n",
    "3. Empirical moment magnitude to rupture area scaling laws (bi-linear Allen and Hayes, 2017)\n",
    "4. Crack theory for rupture shape (circular small earthquakes)\n",
    "5. Geometric fault limits on rupture width and shape\n",
    "6. Estimated roughness of coseismic slip distributions\n",
    "7. Earthquake slip is probabilistically focused on regions with accumulated slip deficits\n",
    "8. Co-seismic and inter-seismic moment balance (can be adjusted for imbalance)\n",
    "9. Geodetically constrained decadal-scale interseismic fault coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import meshio\n",
    "import os\n",
    "import warnings\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "from pprint import pprint\n",
    "from ismember import ismember\n",
    "import matplotlib\n",
    "import skies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_name = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "base_runs_folder = \"./runs/\"\n",
    "output_path = os.path.join(base_runs_folder, run_name)\n",
    "mesh_parameters_file_name = \"western_north_america_mesh_parameters.json\"\n",
    "skies.create_output_folder(base_runs_folder, output_path)\n",
    "meshes = skies.read_meshes(mesh_parameters_file_name)\n",
    "skies.print_magnitude_overview(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial conditions with accumulated slip\n",
    "sources = addict.Dict()\n",
    "sources.lon = np.array([235.779])\n",
    "sources.lat = np.array([45.553])\n",
    "sources.magnitude = np.array([10.0])\n",
    "sources.slip_type = [\"dip_slip\"]\n",
    "initial_slip_deficit = skies.get_synthetic_accumulated_slip(meshes[0], sources)\n",
    "initial_dip_slip_deficit = initial_slip_deficit[1::2]\n",
    "\n",
    "# Load initial slip defict and multiply by time cascadia_low_resolution_tde_dip_slip_rates.npy\n",
    "initial_dip_slip_deficit = np.load(\"cascadia_low_resolution_tde_dip_slip_rates.npy\")\n",
    "\n",
    "total_coseismic_slip = np.zeros_like(initial_dip_slip_deficit)\n",
    "skies.plot_initial_data(meshes, initial_dip_slip_deficit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "pre_event_slip_deficit = initial_dip_slip_deficit\n",
    "for i in range(5):\n",
    "    print(f\"{i=}\")\n",
    "    print(f\"{np.sum(pre_event_slip_deficit > 0)=}\")\n",
    "\n",
    "    # Only go through the event generation process of there is positive slip deficit somewhere\n",
    "    if np.sum(pre_event_slip_deficit > 0) > 0:\n",
    "        location_probability = skies.get_location_probability(pre_event_slip_deficit, t)\n",
    "        event = skies.create_event(meshes, location_probability)\n",
    "        total_coseismic_slip += event.slip_all_elements\n",
    "        post_event_slip_deficit = pre_event_slip_deficit - event.slip_all_elements\n",
    "        # print_event(event, meshes)\n",
    "        skies.plot_event(\n",
    "            event,\n",
    "            meshes,\n",
    "            pre_event_slip_deficit,\n",
    "            location_probability,\n",
    "            post_event_slip_deficit,\n",
    "            t,\n",
    "            i,\n",
    "        )\n",
    "        pre_event_slip_deficit = np.copy(post_event_slip_deficit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: #10 Write up eigenvalue shape idea\n",
    "# TODO: #11 Revisit probability calcuation with sigmoid.  We're generating occasional Nans\n",
    "# TODO: #15 Write up theory for time probability\n",
    "# TODO: #14 Code 1D time series example with: 1) loading, 2) coseismic jumps, 2) Omori like decay after earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D time series experiment\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def get_omori_decay_probability(time_vector, time_of_earthquake, amplitude, decay_time):\n",
    "    omori_decay_probability = amplitude / (\n",
    "        1 + (1 / decay_time) * (time_vector - time_of_earthquake)\n",
    "    )\n",
    "\n",
    "    omori_decay_probability[time_vector < time_of_earthquake] = 0.0\n",
    "    return omori_decay_probability\n",
    "\n",
    "\n",
    "MM2M = 1e-3  # millimeters to meters\n",
    "SECONDS_IN_A_YEAR = 60 * 60 * 24 * 365\n",
    "DAYS_IN_A_YEAR = 365\n",
    "n_years = 30000\n",
    "time_vector = np.linspace(0, n_years, n_years * 1)\n",
    "minimum_probability = 1e-6\n",
    "time_probability = np.zeros_like(time_vector)\n",
    "time_probability_offset = np.zeros_like(time_vector)\n",
    "time_probability = minimum_probability * np.ones_like(time_vector)\n",
    "\n",
    "loading_rate = 30.0  # (mm/yr)\n",
    "earthquake_index_list = []\n",
    "earthquake_magnitude_list = []\n",
    "earthquake_probability_list = []\n",
    "event_trigger_list = []\n",
    "\n",
    "MINIMUM_EVENT_MOMENT_MAGNITUDE = 6.5\n",
    "MAXIMUM_EVENT_MOMENT_MAGNITUDE = 9.0\n",
    "\n",
    "amplitude = 0.01\n",
    "\n",
    "# TODO: #18 Let gutenberg richter accept min and max magnitudes\n",
    "# TODO: Figure out why Omori decay isn't showing up\n",
    "# TODO: Why are all events so large?\n",
    "\n",
    "pre_event_slip_deficit = np.copy(initial_dip_slip_deficit)\n",
    "total_slip_deficit = 10 * np.copy(initial_dip_slip_deficit)\n",
    "total_slip_deficit_scalar = np.zeros_like(time_vector)\n",
    "total_slip_deficit_scalar[0] = np.sum(total_slip_deficit)\n",
    "\n",
    "time_step = 1e-10\n",
    "interseismic_loading_rate = initial_dip_slip_deficit\n",
    "time_probability_step = 0.00005\n",
    "time_probability_step = 1e-10\n",
    "\n",
    "\n",
    "# Main time loop\n",
    "for i in range(0, len(time_vector) - 1):\n",
    "\n",
    "    # Determine whether or not there is an event at this time step\n",
    "    event_trigger = np.random.choice(\n",
    "        2, 1, p=[1 - time_probability[i], time_probability[i]]\n",
    "    )\n",
    "    event_trigger_list.append(event_trigger)\n",
    "\n",
    "    # Do we have an earthquake at this time step?\n",
    "    if bool(event_trigger) and (np.sum(total_slip_deficit) > 0):\n",
    "        print(f\"{i=}\")\n",
    "        # skies.print_event(event, meshes)\n",
    "\n",
    "        # Generate a synthetic earthquake\n",
    "        location_probability = skies.get_location_probability(pre_event_slip_deficit, t)\n",
    "        event = skies.create_event(meshes, location_probability)\n",
    "        # post_event_slip_deficit = pre_event_slip_deficit - event.slip_all_elements\n",
    "\n",
    "        # skies.plot_event(\n",
    "        #     event,\n",
    "        #     meshes,\n",
    "        #     pre_event_slip_deficit,\n",
    "        #     location_probability,\n",
    "        #     post_event_slip_deficit,\n",
    "        #     t,\n",
    "        #     i,\n",
    "        # )\n",
    "\n",
    "        earthquake_magnitude_list.append(event.moment_magnitude)\n",
    "        earthquake_index_list.append(i)\n",
    "        earthquake_probability_list.append(\n",
    "            get_omori_decay_probability(\n",
    "                time_vector, time_vector[i], amplitude, decay_time=100.0\n",
    "            )\n",
    "        )\n",
    "        magnitude_dependent_amplitude = (\n",
    "            amplitude + amplitude * event.moment_magnitude / 500\n",
    "        )\n",
    "\n",
    "        # Update probability of occurence at the next time step\n",
    "        time_probability_offset[i + 1] = (\n",
    "            time_probability_offset[i] + magnitude_dependent_amplitude\n",
    "        )\n",
    "\n",
    "        # Update the total slip deficit mesh\n",
    "        total_slip_deficit = (\n",
    "            total_slip_deficit\n",
    "            + time_step * interseismic_loading_rate\n",
    "            - event.slip_all_elements\n",
    "        )\n",
    "\n",
    "        # Update probability for event occurence at the next time step\n",
    "        time_probability[i + 1] = (\n",
    "            time_probability[i] + time_step + magnitude_dependent_amplitude\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # Update total_slip_deficiyt for the case when there are no earthquakes\n",
    "        total_slip_deficit = total_slip_deficit + time_step * interseismic_loading_rate\n",
    "\n",
    "        # Update time probability for event occurence at the next time step\n",
    "        time_probability[i + 1] = (\n",
    "            time_probability[i] + time_step * np.sum(interseismic_loading_rate)\n",
    "        )\n",
    "\n",
    "        # Sum contribution from all past earthquakes\n",
    "        # TODO: The scaling factor here is magic\n",
    "        for j in range(len(earthquake_index_list)):\n",
    "            time_probability[i + 1] += 1.5 * (\n",
    "                earthquake_probability_list[j][i + 1]\n",
    "                - earthquake_probability_list[j][i]\n",
    "            )\n",
    "\n",
    "    # Update the total slip deficit scalar\n",
    "    total_slip_deficit_scalar[i + 1] = np.sum(total_slip_deficit)\n",
    "\n",
    "    # Pre-event slip deficit for next time step\n",
    "    pre_event_slip_deficit = np.copy(total_slip_deficit)\n",
    "\n",
    "    # Catch probabilities less than zero\n",
    "    if time_probability[i + 1] < minimum_probability:\n",
    "        time_probability[i + 1] = minimum_probability\n",
    "\n",
    "    # Catch probabilities greater than one\n",
    "    if time_probability[i + 1] >= 1.0:\n",
    "        print(f\"time_probability exceeds 1.0 at step {i}\")\n",
    "        break\n",
    "\n",
    "print(np.where(np.array(event_trigger_list) == 1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "end_idx = 30000\n",
    "figsize = (15, 3)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(time_vector[start_idx:end_idx], total_slip_deficit_scalar[start_idx:end_idx], linewidth=0.5)\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"$\\hat{s}_\\mathrm{d}$\")\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(time_vector[start_idx:end_idx], time_probability[start_idx:end_idx], linewidth=0.5)\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"$P(t)$\")\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(event_trigger_list[start_idx:end_idx], \"r.\")\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"event_trigger\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-log plot\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(time_vector, time_probability, \"-k\", linewidth=0.5, zorder=15)\n",
    "for i in range(len(earthquake_index_list)):\n",
    "    plt.plot(\n",
    "        time_vector[earthquake_index_list[i]],\n",
    "        time_probability[earthquake_index_list[i]],\n",
    "        \".k\",\n",
    "        markersize=5,\n",
    "        linewidth=0.0,\n",
    "        zorder=20,\n",
    "    )\n",
    "plt.fill(\n",
    "    np.append(time_vector, 0),\n",
    "    np.append(time_probability, minimum_probability),\n",
    "    color=\"orange\",\n",
    "    alpha=1.0,\n",
    "    edgecolor=None,\n",
    ")\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.xlim([np.min(time_vector), np.max(time_vector)])\n",
    "plt.ylim([0, 0.11])\n",
    "plt.grid(True, linewidth=0.5, linestyle=\"--\")\n",
    "# plt.savefig(\"example_probability_time_series.pdf\")\n",
    "# plt.savefig(\"example_probability_time_series.png\", dpi=500)\n",
    "plt.show()\n",
    "\n",
    "# Semilogy plot\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.semilogy(time_vector, time_probability, \"-k\", linewidth=0.5, zorder=15)\n",
    "# for i in range(len(earthquake_index_list)):\n",
    "#     plt.plot(\n",
    "#         time_vector[earthquake_index_list[i]],\n",
    "#         time_probability[earthquake_index_list[i]],\n",
    "#         \".k\",\n",
    "#         markersize=10 ** (earthquake_magnitude_list[i] - 6),\n",
    "#         alpha=0.5,\n",
    "#         linewidth=0.0,\n",
    "#         zorder=20,\n",
    "#         color=\"orange\",\n",
    "#         markeredgecolor=\"k\",\n",
    "#     )\n",
    "\n",
    "for i in range(len(earthquake_index_list)):\n",
    "    plt.plot(\n",
    "        time_vector[earthquake_index_list[i]],\n",
    "        time_probability[earthquake_index_list[i]],\n",
    "        \".k\",\n",
    "        markersize=8,\n",
    "        alpha=1.0,\n",
    "        linewidth=0.0,\n",
    "        zorder=20,\n",
    "        markeredgecolor=\"k\",\n",
    "    )\n",
    "\n",
    "plt.fill(\n",
    "    np.append(time_vector, 0),\n",
    "    np.append(time_probability, minimum_probability),\n",
    "    color=\"lightsteelblue\",\n",
    "    alpha=1.0,\n",
    "    edgecolor=None,\n",
    "    zorder=10,\n",
    ")\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.xlim([np.min(time_vector), np.max(time_vector)])\n",
    "plt.ylim([minimum_probability, 1])\n",
    "plt.grid(True, linewidth=0.5, linestyle=\"--\")\n",
    "# plt.savefig(\"example_probability_time_series_semilogy.pdf\")\n",
    "# plt.savefig(\"example_probability_time_series_semilogy.png\", dpi=500)\n",
    "plt.show()\n",
    "\n",
    "# Earthquake magnitude plot\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "for i in range(len(earthquake_index_list)):\n",
    "    plt.plot(\n",
    "        [time_vector[earthquake_index_list[i]], time_vector[earthquake_index_list[i]]],\n",
    "        [6.0, earthquake_magnitude_list[i]],\n",
    "        \"-\",\n",
    "        # markersize=10**(earthquake_magnitude_list[i] - 6),\n",
    "        linewidth=0.5,\n",
    "        zorder=10,\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "\n",
    "for i in range(len(earthquake_index_list)):\n",
    "    plt.plot(\n",
    "        time_vector[earthquake_index_list[i]],\n",
    "        earthquake_magnitude_list[i],\n",
    "        \".\",\n",
    "        markersize=10**(earthquake_magnitude_list[i] - 6),\n",
    "        # markersize=10,\n",
    "        alpha=1.0,\n",
    "        linewidth=0.0,\n",
    "        zorder=20,\n",
    "        color=\"orange\",\n",
    "        markeredgecolor=\"k\",\n",
    "        markeredgewidth=0.5,\n",
    "    )\n",
    "plt.xlabel(\"time index\")\n",
    "plt.ylabel(\"magnitude\")\n",
    "plt.xlim([np.min(time_vector), np.max(time_vector)])\n",
    "plt.ylim([6, 9])\n",
    "plt.grid(True, linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "# plt.savefig(\"example_magnitude_time_series_semilogy.pdf\")\n",
    "# plt.savefig(\"example_magnitude_time_series_semilogy.png\", dpi=500)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('skies')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "958557df22cbe81e98d59acf449326e362496737a00c7832d7d66de975b82f73"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
